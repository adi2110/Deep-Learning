{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MTECH_DS_D021_DL_A7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyaq5AczwBEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "ff3d69ea-ab7b-4d6c-bb2c-b0b0d71f74df"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, AveragePooling2D, Dropout\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "(X_train,y_train),(X_test,y_test)=cifar10.load_data()\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "X_train=X_train.astype('float32')\n",
        "X_test=X_test.astype('float32')\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "X_train,X_test=X_train/255.0,X_test/255.0\n",
        "\n",
        "y_train=to_categorical(y_train,10)\n",
        "y_test=to_categorical(y_test,10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feOKrwSumkZP",
        "colab_type": "text"
      },
      "source": [
        "## **LeNet-5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZfsnrTZln_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "78d83466-78a1-42a3-83c7-1f233576129f"
      },
      "source": [
        "model_lenet5 = Sequential()\n",
        "\n",
        "model_lenet5.add(Conv2D(filters=6,kernel_size=(5,5),strides=(1,1),padding=\"valid\",activation=\"sigmoid\",input_shape=(32,32,3)))\n",
        "model_lenet5.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_lenet5.add(Conv2D(filters=16,kernel_size=(5,5),strides=(1,1),padding=\"valid\",activation=\"sigmoid\"))\n",
        "model_lenet5.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_lenet5.add(Flatten())\n",
        "\n",
        "model_lenet5.add(Dense(units=120,activation='sigmoid'))\n",
        "model_lenet5.add(Dense(units=84,activation='sigmoid'))\n",
        "model_lenet5.add(Dense(units=10,activation='softmax'))\n",
        "\n",
        "model_lenet5.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 6)         456       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               48120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cwkdojdnZhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_lenet5.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVuqu6ejnhpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23e29da2-7266-4dc1-8f6c-b2bdb7f03c87"
      },
      "source": [
        "model_lenet5.fit(X_train, y_train, epochs=100, batch_size=64, steps_per_epoch=120, validation_split=0.3)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 1.2465 - accuracy: 0.5732 - val_loss: 1.2957 - val_accuracy: 0.5421\n",
            "Epoch 2/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2321 - accuracy: 0.5724 - val_loss: 1.3006 - val_accuracy: 0.5381\n",
            "Epoch 3/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2334 - accuracy: 0.5730 - val_loss: 1.3064 - val_accuracy: 0.5384\n",
            "Epoch 4/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2211 - accuracy: 0.5746 - val_loss: 1.3064 - val_accuracy: 0.5375\n",
            "Epoch 5/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2302 - accuracy: 0.5706 - val_loss: 1.3024 - val_accuracy: 0.5379\n",
            "Epoch 6/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2074 - accuracy: 0.5734 - val_loss: 1.3083 - val_accuracy: 0.5345\n",
            "Epoch 7/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2160 - accuracy: 0.5848 - val_loss: 1.3222 - val_accuracy: 0.5347\n",
            "Epoch 8/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2146 - accuracy: 0.5801 - val_loss: 1.2775 - val_accuracy: 0.5473\n",
            "Epoch 9/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2245 - accuracy: 0.5724 - val_loss: 1.2716 - val_accuracy: 0.5474\n",
            "Epoch 10/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2090 - accuracy: 0.5791 - val_loss: 1.2991 - val_accuracy: 0.5419\n",
            "Epoch 11/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2050 - accuracy: 0.5794 - val_loss: 1.2867 - val_accuracy: 0.5455\n",
            "Epoch 12/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1930 - accuracy: 0.5871 - val_loss: 1.2739 - val_accuracy: 0.5498\n",
            "Epoch 13/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2178 - accuracy: 0.5723 - val_loss: 1.3098 - val_accuracy: 0.5434\n",
            "Epoch 14/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2022 - accuracy: 0.5828 - val_loss: 1.2845 - val_accuracy: 0.5487\n",
            "Epoch 15/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.2006 - accuracy: 0.5846 - val_loss: 1.2776 - val_accuracy: 0.5499\n",
            "Epoch 16/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1835 - accuracy: 0.5832 - val_loss: 1.2610 - val_accuracy: 0.5535\n",
            "Epoch 17/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1797 - accuracy: 0.5875 - val_loss: 1.2770 - val_accuracy: 0.5480\n",
            "Epoch 18/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1777 - accuracy: 0.5876 - val_loss: 1.2676 - val_accuracy: 0.5521\n",
            "Epoch 19/100\n",
            "120/120 [==============================] - 2s 13ms/step - loss: 1.1952 - accuracy: 0.5837 - val_loss: 1.2807 - val_accuracy: 0.5481\n",
            "Epoch 20/100\n",
            "120/120 [==============================] - 2s 13ms/step - loss: 1.1623 - accuracy: 0.5940 - val_loss: 1.2593 - val_accuracy: 0.5561\n",
            "Epoch 21/100\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 1.1568 - accuracy: 0.5915 - val_loss: 1.2640 - val_accuracy: 0.5539\n",
            "Epoch 22/100\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 1.1873 - accuracy: 0.5896 - val_loss: 1.2682 - val_accuracy: 0.5523\n",
            "Epoch 23/100\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 1.1911 - accuracy: 0.5769 - val_loss: 1.2578 - val_accuracy: 0.5551\n",
            "Epoch 24/100\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 1.1434 - accuracy: 0.6027 - val_loss: 1.2790 - val_accuracy: 0.5466\n",
            "Epoch 25/100\n",
            "120/120 [==============================] - 2s 13ms/step - loss: 1.1620 - accuracy: 0.5918 - val_loss: 1.2553 - val_accuracy: 0.5548\n",
            "Epoch 26/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1730 - accuracy: 0.5852 - val_loss: 1.2494 - val_accuracy: 0.5601\n",
            "Epoch 27/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1677 - accuracy: 0.5921 - val_loss: 1.2478 - val_accuracy: 0.5591\n",
            "Epoch 28/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1529 - accuracy: 0.5993 - val_loss: 1.2623 - val_accuracy: 0.5545\n",
            "Epoch 29/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1411 - accuracy: 0.5984 - val_loss: 1.2633 - val_accuracy: 0.5547\n",
            "Epoch 30/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1596 - accuracy: 0.5891 - val_loss: 1.2503 - val_accuracy: 0.5573\n",
            "Epoch 31/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1348 - accuracy: 0.6033 - val_loss: 1.2434 - val_accuracy: 0.5593\n",
            "Epoch 32/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1675 - accuracy: 0.5906 - val_loss: 1.2450 - val_accuracy: 0.5621\n",
            "Epoch 33/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1189 - accuracy: 0.6124 - val_loss: 1.2473 - val_accuracy: 0.5574\n",
            "Epoch 34/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1411 - accuracy: 0.5928 - val_loss: 1.2356 - val_accuracy: 0.5625\n",
            "Epoch 35/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1663 - accuracy: 0.5922 - val_loss: 1.2372 - val_accuracy: 0.5624\n",
            "Epoch 36/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1377 - accuracy: 0.6021 - val_loss: 1.2404 - val_accuracy: 0.5636\n",
            "Epoch 37/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1135 - accuracy: 0.6084 - val_loss: 1.2363 - val_accuracy: 0.5649\n",
            "Epoch 38/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1306 - accuracy: 0.6090 - val_loss: 1.2471 - val_accuracy: 0.5590\n",
            "Epoch 39/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1209 - accuracy: 0.6016 - val_loss: 1.2466 - val_accuracy: 0.5613\n",
            "Epoch 40/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1164 - accuracy: 0.6069 - val_loss: 1.2455 - val_accuracy: 0.5597\n",
            "Epoch 41/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1401 - accuracy: 0.6040 - val_loss: 1.2420 - val_accuracy: 0.5618\n",
            "Epoch 42/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1075 - accuracy: 0.6087 - val_loss: 1.2338 - val_accuracy: 0.5637\n",
            "Epoch 43/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1178 - accuracy: 0.6083 - val_loss: 1.2348 - val_accuracy: 0.5657\n",
            "Epoch 44/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0998 - accuracy: 0.6124 - val_loss: 1.2301 - val_accuracy: 0.5641\n",
            "Epoch 45/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1198 - accuracy: 0.6007 - val_loss: 1.2356 - val_accuracy: 0.5679\n",
            "Epoch 46/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1114 - accuracy: 0.6075 - val_loss: 1.2362 - val_accuracy: 0.5659\n",
            "Epoch 47/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0874 - accuracy: 0.6216 - val_loss: 1.2391 - val_accuracy: 0.5595\n",
            "Epoch 48/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0968 - accuracy: 0.6146 - val_loss: 1.2528 - val_accuracy: 0.5575\n",
            "Epoch 49/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1171 - accuracy: 0.6108 - val_loss: 1.2790 - val_accuracy: 0.5528\n",
            "Epoch 50/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1050 - accuracy: 0.6129 - val_loss: 1.2164 - val_accuracy: 0.5671\n",
            "Epoch 51/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0753 - accuracy: 0.6207 - val_loss: 1.2429 - val_accuracy: 0.5612\n",
            "Epoch 52/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0906 - accuracy: 0.6087 - val_loss: 1.2489 - val_accuracy: 0.5573\n",
            "Epoch 53/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1045 - accuracy: 0.6134 - val_loss: 1.2316 - val_accuracy: 0.5658\n",
            "Epoch 54/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0863 - accuracy: 0.6202 - val_loss: 1.2620 - val_accuracy: 0.5599\n",
            "Epoch 55/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0937 - accuracy: 0.6122 - val_loss: 1.2066 - val_accuracy: 0.5729\n",
            "Epoch 56/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0674 - accuracy: 0.6241 - val_loss: 1.2415 - val_accuracy: 0.5657\n",
            "Epoch 57/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0848 - accuracy: 0.6164 - val_loss: 1.2125 - val_accuracy: 0.5754\n",
            "Epoch 58/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0587 - accuracy: 0.6268 - val_loss: 1.2267 - val_accuracy: 0.5695\n",
            "Epoch 59/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1051 - accuracy: 0.6147 - val_loss: 1.2273 - val_accuracy: 0.5698\n",
            "Epoch 60/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0630 - accuracy: 0.6290 - val_loss: 1.2126 - val_accuracy: 0.5726\n",
            "Epoch 61/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0538 - accuracy: 0.6262 - val_loss: 1.2206 - val_accuracy: 0.5714\n",
            "Epoch 62/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0645 - accuracy: 0.6208 - val_loss: 1.2127 - val_accuracy: 0.5718\n",
            "Epoch 63/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0613 - accuracy: 0.6260 - val_loss: 1.2201 - val_accuracy: 0.5723\n",
            "Epoch 64/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0773 - accuracy: 0.6190 - val_loss: 1.2023 - val_accuracy: 0.5750\n",
            "Epoch 65/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0480 - accuracy: 0.6307 - val_loss: 1.2259 - val_accuracy: 0.5703\n",
            "Epoch 66/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0634 - accuracy: 0.6293 - val_loss: 1.2227 - val_accuracy: 0.5705\n",
            "Epoch 67/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0650 - accuracy: 0.6250 - val_loss: 1.2197 - val_accuracy: 0.5700\n",
            "Epoch 68/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0554 - accuracy: 0.6322 - val_loss: 1.2260 - val_accuracy: 0.5687\n",
            "Epoch 69/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0452 - accuracy: 0.6285 - val_loss: 1.2120 - val_accuracy: 0.5745\n",
            "Epoch 70/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0313 - accuracy: 0.6430 - val_loss: 1.2329 - val_accuracy: 0.5700\n",
            "Epoch 71/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0543 - accuracy: 0.6294 - val_loss: 1.2152 - val_accuracy: 0.5769\n",
            "Epoch 72/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0251 - accuracy: 0.6365 - val_loss: 1.2348 - val_accuracy: 0.5685\n",
            "Epoch 73/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0743 - accuracy: 0.6220 - val_loss: 1.2023 - val_accuracy: 0.5768\n",
            "Epoch 74/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0296 - accuracy: 0.6406 - val_loss: 1.2130 - val_accuracy: 0.5727\n",
            "Epoch 75/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0337 - accuracy: 0.6337 - val_loss: 1.2012 - val_accuracy: 0.5783\n",
            "Epoch 76/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0298 - accuracy: 0.6454 - val_loss: 1.2095 - val_accuracy: 0.5735\n",
            "Epoch 77/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0217 - accuracy: 0.6432 - val_loss: 1.1985 - val_accuracy: 0.5783\n",
            "Epoch 78/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0309 - accuracy: 0.6392 - val_loss: 1.2005 - val_accuracy: 0.5775\n",
            "Epoch 79/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0167 - accuracy: 0.6401 - val_loss: 1.2121 - val_accuracy: 0.5791\n",
            "Epoch 80/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0324 - accuracy: 0.6354 - val_loss: 1.2278 - val_accuracy: 0.5712\n",
            "Epoch 81/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0079 - accuracy: 0.6496 - val_loss: 1.2073 - val_accuracy: 0.5775\n",
            "Epoch 82/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0223 - accuracy: 0.6465 - val_loss: 1.2179 - val_accuracy: 0.5782\n",
            "Epoch 83/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0066 - accuracy: 0.6475 - val_loss: 1.2039 - val_accuracy: 0.5765\n",
            "Epoch 84/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 0.9891 - accuracy: 0.6458 - val_loss: 1.2292 - val_accuracy: 0.5664\n",
            "Epoch 85/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0320 - accuracy: 0.6405 - val_loss: 1.2138 - val_accuracy: 0.5752\n",
            "Epoch 86/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0032 - accuracy: 0.6445 - val_loss: 1.2142 - val_accuracy: 0.5773\n",
            "Epoch 87/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0191 - accuracy: 0.6427 - val_loss: 1.1938 - val_accuracy: 0.5793\n",
            "Epoch 88/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 0.9908 - accuracy: 0.6453 - val_loss: 1.2057 - val_accuracy: 0.5795\n",
            "Epoch 89/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0010 - accuracy: 0.6486 - val_loss: 1.2352 - val_accuracy: 0.5652\n",
            "Epoch 90/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0034 - accuracy: 0.6521 - val_loss: 1.2042 - val_accuracy: 0.5778\n",
            "Epoch 91/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 0.9889 - accuracy: 0.6517 - val_loss: 1.2175 - val_accuracy: 0.5742\n",
            "Epoch 92/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 0.9835 - accuracy: 0.6577 - val_loss: 1.1819 - val_accuracy: 0.5872\n",
            "Epoch 93/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 0.9881 - accuracy: 0.6525 - val_loss: 1.2034 - val_accuracy: 0.5816\n",
            "Epoch 94/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 0.9845 - accuracy: 0.6525 - val_loss: 1.2014 - val_accuracy: 0.5815\n",
            "Epoch 95/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 0.9900 - accuracy: 0.6526 - val_loss: 1.1829 - val_accuracy: 0.5839\n",
            "Epoch 96/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 0.9973 - accuracy: 0.6521 - val_loss: 1.1940 - val_accuracy: 0.5811\n",
            "Epoch 97/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 0.9900 - accuracy: 0.6527 - val_loss: 1.2060 - val_accuracy: 0.5853\n",
            "Epoch 98/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 0.9887 - accuracy: 0.6556 - val_loss: 1.2100 - val_accuracy: 0.5795\n",
            "Epoch 99/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 0.9760 - accuracy: 0.6551 - val_loss: 1.2154 - val_accuracy: 0.5795\n",
            "Epoch 100/100\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 0.9904 - accuracy: 0.6493 - val_loss: 1.1847 - val_accuracy: 0.5877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffab00d3e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fkvgQ4monxF",
        "colab_type": "text"
      },
      "source": [
        "##**VGG-16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRgi3U83n0Iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "outputId": "85b3dc59-13b0-4d53-93c1-26256db21c7d"
      },
      "source": [
        "model_vgg16=Sequential()\n",
        "\n",
        "model_vgg16.add(Conv2D(filters=64,kernel_size=(3,3),strides=(2,2),padding=\"same\",activation=\"relu\",input_shape=(32,32,3)))\n",
        "model_vgg16.add(Conv2D(filters=64,kernel_size=(3,3),strides=(2,2),padding=\"same\",activation=\"relu\"))\n",
        "model_vgg16.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_vgg16.add(Conv2D(filters=128,kernel_size=(3,3),strides=(2,2),padding=\"same\",activation=\"relu\"))\n",
        "model_vgg16.add(Conv2D(filters=128,kernel_size=(3,3),strides=(2,2),padding=\"same\",activation=\"relu\"))\n",
        "model_vgg16.add(MaxPooling2D(pool_size=(2,2),padding=\"same\"))\n",
        "\n",
        "model_vgg16.add(Conv2D(filters=256,kernel_size=(3,3),strides=(2,2),padding=\"same\",activation=\"relu\"))\n",
        "model_vgg16.add(Conv2D(filters=256,kernel_size=(3,3),strides=(2,2),padding=\"same\",activation=\"relu\"))\n",
        "model_vgg16.add(Conv2D(filters=256,kernel_size=(3,3),strides=(2,2),padding=\"same\",activation=\"relu\"))\n",
        "model_vgg16.add(MaxPooling2D(pool_size=(2,2),padding=\"same\"))\n",
        "\n",
        "model_vgg16.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "model_vgg16.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "model_vgg16.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "model_vgg16.add(MaxPooling2D(pool_size=(2,2),padding=\"same\"))\n",
        "\n",
        "model_vgg16.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "model_vgg16.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "model_vgg16.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "model_vgg16.add(MaxPooling2D(pool_size=(2,2),padding=\"same\"))\n",
        "\n",
        "model_vgg16.add(Flatten())\n",
        "\n",
        "model_vgg16.add(Dense(units=128,activation='relu'))\n",
        "model_vgg16.add(Dense(units=64,activation='relu'))\n",
        "model_vgg16.add(Dense(units=10,activation='softmax'))\n",
        "\n",
        "model_vgg16.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        1792      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 1, 1, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 1, 1, 256)         590080    \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 1, 1, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 14,789,258\n",
            "Trainable params: 14,789,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAXI4FVBpJed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_vgg16.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVz4vEf1pTIo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1653e47-8927-4d3f-e085-eea09561b3cb"
      },
      "source": [
        "model_vgg16.fit(X_train, y_train, epochs=100, batch_size=64, steps_per_epoch=120, validation_data=(X_test,y_test), verbose = 1) #,steps_per_epoch=1000"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/120 [..............................] - ETA: 6s - loss: 2.3032 - accuracy: 0.1016WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0245s vs `on_train_batch_end` time: 0.0422s). Check your callbacks.\n",
            "120/120 [==============================] - 8s 66ms/step - loss: 2.3028 - accuracy: 0.0999 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.0944 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.1013 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3029 - accuracy: 0.0953 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 5/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.0987 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3033 - accuracy: 0.0953 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 7/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3029 - accuracy: 0.0998 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 8/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3029 - accuracy: 0.1029 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 9/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0999 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 10/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3033 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 12/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3029 - accuracy: 0.0969 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 13/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 14/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.1002 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 15/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.1013 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 16/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0979 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 17/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3027 - accuracy: 0.1053 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 18/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.1008 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 19/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3032 - accuracy: 0.0970 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 20/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3032 - accuracy: 0.0963 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 21/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3028 - accuracy: 0.0996 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 22/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 23/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3028 - accuracy: 0.1038 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 24/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 25/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 26/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3029 - accuracy: 0.0962 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 27/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3029 - accuracy: 0.0971 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 28/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3032 - accuracy: 0.0986 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 29/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3029 - accuracy: 0.0970 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 30/100\n",
            "120/120 [==============================] - 8s 66ms/step - loss: 2.3031 - accuracy: 0.1035 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 31/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0980 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 32/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3029 - accuracy: 0.0997 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 33/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3033 - accuracy: 0.0960 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 34/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 35/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0938 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 36/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3032 - accuracy: 0.0938 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 37/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3025 - accuracy: 0.1034 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 38/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3034 - accuracy: 0.0962 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 39/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3029 - accuracy: 0.0990 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 40/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3032 - accuracy: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 41/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.0938 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 42/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0965 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 43/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 44/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3029 - accuracy: 0.1008 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 45/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3032 - accuracy: 0.0964 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 46/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3028 - accuracy: 0.1006 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 47/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3029 - accuracy: 0.0970 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 48/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3034 - accuracy: 0.0930 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 49/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3029 - accuracy: 0.0974 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 50/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3030 - accuracy: 0.1034 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 51/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3031 - accuracy: 0.0953 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 52/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3030 - accuracy: 0.1010 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 53/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.0997 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 54/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3028 - accuracy: 0.1065 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 55/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3031 - accuracy: 0.0995 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 56/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.0971 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 57/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3029 - accuracy: 0.0960 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 58/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3033 - accuracy: 0.1004 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 59/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0985 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 60/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.1009 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 61/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3032 - accuracy: 0.0944 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 62/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 63/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 64/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.0991 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 65/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.0960 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 66/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3032 - accuracy: 0.0980 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 67/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0999 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 68/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3028 - accuracy: 0.1016 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
            "Epoch 69/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.1047 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 70/100\n",
            "120/120 [==============================] - 8s 66ms/step - loss: 2.3032 - accuracy: 0.0956 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 71/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3029 - accuracy: 0.1005 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 72/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3029 - accuracy: 0.1019 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 73/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0986 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 74/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.1005 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 75/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3032 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 76/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.1005 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 77/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3034 - accuracy: 0.0906 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 78/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0991 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 79/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.0987 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 80/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3031 - accuracy: 0.0974 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 81/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3027 - accuracy: 0.0961 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 82/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0979 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 83/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3032 - accuracy: 0.0965 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 84/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3027 - accuracy: 0.1023 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
            "Epoch 85/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3032 - accuracy: 0.1031 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 86/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3025 - accuracy: 0.1077 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 87/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3033 - accuracy: 0.0964 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 88/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3030 - accuracy: 0.0977 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 89/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3028 - accuracy: 0.1027 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 90/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3030 - accuracy: 0.0988 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 91/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3031 - accuracy: 0.0931 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 92/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3030 - accuracy: 0.0992 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 93/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.1038 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 94/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3030 - accuracy: 0.0974 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 95/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3029 - accuracy: 0.0971 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 96/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3032 - accuracy: 0.1027 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 97/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3031 - accuracy: 0.0987 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 98/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3032 - accuracy: 0.1004 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 99/100\n",
            "120/120 [==============================] - 8s 65ms/step - loss: 2.3031 - accuracy: 0.0977 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 100/100\n",
            "120/120 [==============================] - 8s 64ms/step - loss: 2.3030 - accuracy: 0.1000 - val_loss: 2.3028 - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffa5ec37a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6xgZsKLsazH",
        "colab_type": "text"
      },
      "source": [
        "##**AlexNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrKf2skhpqZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "afd01fcd-fc0d-4f57-e1ee-71ff67455029"
      },
      "source": [
        "model_alexnet=Sequential()\n",
        "\n",
        "model_alexnet.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding=\"same\",activation=\"relu\",input_shape=(32,32,3)))\n",
        "model_alexnet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"valid\"))\n",
        "\n",
        "model_alexnet.add(Conv2D(filters=256,kernel_size=(11,11),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "model_alexnet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"valid\"))\n",
        "\n",
        "model_alexnet.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "model_alexnet.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "model_alexnet.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "model_alexnet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"valid\"))\n",
        "\n",
        "model_alexnet.add(Flatten())\n",
        "model_alexnet.add(Dense(units=4096,input_shape=(32*32*3,),activation='relu'))\n",
        "model_alexnet.add(Dropout(0.4))\n",
        "model_alexnet.add(Dense(units=4096,activation='relu'))\n",
        "model_alexnet.add(Dropout(0.4))\n",
        "model_alexnet.add(Dense(units=1000,activation='relu'))\n",
        "model_alexnet.add(Dropout(0.4))\n",
        "model_alexnet.add(Dense(units=10,activation='softmax'))\n",
        "\n",
        "model_alexnet.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 8, 8, 96)          34944     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 4, 4, 256)         2973952   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 28,047,490\n",
            "Trainable params: 28,047,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2V29y1lsuZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_alexnet.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJImrmWrsysv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4bc63f5d-7148-4182-e7a0-b9de0df1cfc3"
      },
      "source": [
        "model_alexnet.fit(X_train,y_train,epochs=50,batch_size=128,steps_per_epoch=150,validation_data=(X_test,y_test),verbose = 1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "  2/150 [..............................] - ETA: 4s - loss: 2.3084 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0178s vs `on_train_batch_end` time: 0.0376s). Check your callbacks.\n",
            "150/150 [==============================] - 9s 62ms/step - loss: 2.3011 - accuracy: 0.1051 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 2/50\n",
            "150/150 [==============================] - 9s 59ms/step - loss: 2.3052 - accuracy: 0.1032 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 3/50\n",
            "150/150 [==============================] - 10s 64ms/step - loss: 2.3017 - accuracy: 0.0993 - val_loss: 2.3030 - val_accuracy: 0.0999\n",
            "Epoch 4/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3030 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 5/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 6/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 7/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3029 - accuracy: 0.0921 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 8/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 9/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3028 - accuracy: 0.0958 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 10/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3028 - accuracy: 0.0950 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 11/50\n",
            "150/150 [==============================] - 9s 59ms/step - loss: 2.3027 - accuracy: 0.0950 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 12/50\n",
            "150/150 [==============================] - 9s 59ms/step - loss: 2.3027 - accuracy: 0.0995 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 13/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 14/50\n",
            "150/150 [==============================] - 9s 59ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 15/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 16/50\n",
            "150/150 [==============================] - 9s 59ms/step - loss: 2.3028 - accuracy: 0.0953 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 17/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.1003 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 18/50\n",
            "150/150 [==============================] - 9s 59ms/step - loss: 2.3027 - accuracy: 0.0961 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 19/50\n",
            "150/150 [==============================] - 9s 59ms/step - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 20/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0966 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 21/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 22/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 23/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0933 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 24/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 25/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3026 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 26/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 27/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3025 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 28/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3028 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 29/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 30/50\n",
            "150/150 [==============================] - 9s 59ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 31/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 32/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 33/50\n",
            "150/150 [==============================] - 9s 59ms/step - loss: 2.3027 - accuracy: 0.0961 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 34/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0966 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 35/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 36/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3028 - accuracy: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 37/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 38/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 39/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0944 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 40/50\n",
            "150/150 [==============================] - 9s 61ms/step - loss: 2.3027 - accuracy: 0.0974 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 41/50\n",
            "150/150 [==============================] - 9s 61ms/step - loss: 2.3026 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 42/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3028 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 43/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 44/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 45/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 46/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.1013 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 47/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3027 - accuracy: 0.0970 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 48/50\n",
            "150/150 [==============================] - 9s 60ms/step - loss: 2.3026 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 49/50\n",
            "150/150 [==============================] - 9s 59ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 50/50\n",
            "150/150 [==============================] - 9s 59ms/step - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffa5cbc6668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAK8S2l0tEaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}